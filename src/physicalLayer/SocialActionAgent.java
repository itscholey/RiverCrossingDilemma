package physicalLayer;

import java.util.ArrayList;

import deliberativeLayer.DecisionNetwork;
import engine.Engine;
import reactiveLayer.Neuron;

/**
 * An implementation of the Agent abstract class capable of social action, where social action is operationalised as:
 * <ul>
 * 	<li>goal-rational action, where the action taken is considered to be the most likely to achieve a goal;</li>
 * 	<li>traditional action, where the action taken is comparable to the representative state of the population at the current timestep;</li>
 * 	<li>random action, where the action taken is completely random.</li>
 * </ul>
 * 
 * A SocialActionAgent is situated in an environment, that has a two-layered neural network architecture for learning
 * and decision-making. Sub-goals are generated by the deliberative layer, and these sub-goals are actioned by the 
 * reactive layer which decides on the immediate next steps based on the chosen sub-goals.
 * 
 * @author Chloe M. Barnes
 * @version v1.2
 */
public class SocialActionAgent extends Agent {
	/**
	 * Creates an agent capable of social action with an initial location in its environment, empty decision-making layers (random genes)
	 * and no allocated targets.
	 * 
	 * @param cell The initial location of the agent in the environment. 
	 * @param rows The number of rows in the environment.
	 * @param cols The number of columns in the environment.
	 */
	public SocialActionAgent(Cell cell, int rows, int cols) {
		super(cell, rows, cols);
	}
	
	/**
	 * Creates an agent capable of social action, with no initial location in its environment, empty decision-making layers (random genes)
	 * and no allocated targets.
	 * 
	 * @param rows The number of rows in the environment.
	 * @param cols The number of columns in the environment.
	 */
	public SocialActionAgent(int rows, int cols) {
		super(rows, cols);
	}
	
	/**
	 * Creates an agent capable of social action, with no initial location, populated with given genes in the deliberative layer, an empty
	 * reactive layer and no allocated targets. 
	 * TODO
	 * @param rows The number of rows in the environment.
	 * @param cols The number of cols in the environment.
	 * @param genes A 3D array containing the genes to populate the new agent with.
	 */
	public SocialActionAgent(int rows, int cols, double[][][] genes, int[][] nns) {
		super(rows, cols, genes, nns);
	}
	
	/**
	 * {@inheritDoc} TODO
	 */
	@Override
	public Agent produceOffspring(Agent other) {
		DecisionNetwork os = decisionNetwork.createOffspring(other.getGenes(), other.getNeurons());
		return new SocialActionAgent(rows, cols, os.getGenes(), os.getNeurons());
	}

	/**
	 * Creates a new offspring with no initial location, which is a representative state of the population 
	 * at the current timestep, using the median weights across all agents in the population.
	 *  	 TODO
	 * @param genes The genes of the population to elicit "tradition" from.
	 * @return A new agent that is a representative state of the population at the current timestep, which is initialised
	 * 		with the median weights of the population.
	 */
	@Override
	public Agent produceTraditionalOffspring(ArrayList<double[][][]> genes) {
		double[][][] commonGenes = decisionNetwork.getCommonGenes(genes);
		SocialActionAgent offspring = new SocialActionAgent(rows, cols, commonGenes, getNeurons()); // agent is created with neurons of current agent
		return offspring;
	}
	
	/**
	 * Calculates the fitness based on how many Resources have been collected, how many Stones were placed in the river (and
	 * subsequently how much energy was exerted by the cost incurred), and any penalties for loss of life. The number of moves
	 * is not currently considered in the fitness measure. This purposefully doesn't "lead" the evolution via fitness.
	 * 
	 * @param maxMoves The maximum number of moves that an Agent can take in an environment.
	 * @return A value representing the fitness based on performance and status.
	 */
	@Override
	public Double evaluate(int maxMoves) {
		Double result = (resourcesFound * 0.5) - (((numStones/2.0) * (1 + numStones)) * 0.1);
		if (!isAlive) result -= 1;		
		fitness = result;
		return result;
	}
	
	/** 
	 * Performs actions to be taken in a single move in a single timestep, based on the current state.
	 * Decisions are based on the current status (what cell it is on, whether it is carrying a stone, whether a bridge is partially built),
	 * where a hill-climbing approach is used to achieve sub-goals (via the reactive layer). 
	 * If the cell to move to contains a Stone, then it will automatically be picked up. Likewise, if a Stone is being carried and then the cell
	 * to move to is Water, the Stone will automatically be dropped and a bridge will be made.
	 * 
	 * @param status An array representing the current status: grass, resource, stone, water, carrying status, partial bridge built, where value is 1 if true and 0 otherwise.
	 * @param grid The current state of the environment.
	 * @return The updated state of the environment including the new location of the Agent.
	 * @see reactiveLayer.ReactiveLayer
	 * @see deliberativeLayer.DecisionNetwork
	 */
	@Override
	public Cell[][] move(double[] status, Cell[][] grid) {
		// if the goal has not yet been met
		if (!achievedGoal) {
			double[] decisionOutput = decisionNetwork.forward(status);			
			reactiveLayer.updateActivations(decisionOutput, partialBridgeExists, grid);
			// hold the viable locations for the next move in the surrounding 8 cells
			ArrayList<Neuron> results = new ArrayList<Neuron>();
			// retrieve the neighbouring cells to decide where to move next
			Neuron[] neighbourLandscape = reactiveLayer.getNeighbourLandscape(cell.getLocation());
			
			/* if 1, pick up - if not carrying already
			 * if -1. put down - if carrying something
			 * move after and otherwise */
			if ((!carrying) && grid[cell.getLocation().toArray()[0]][cell.getLocation().toArray()[1]].getObject() instanceof Stone) {
				carrying = true;
				hasCarried = true;
				carriedObject = grid[cell.getLocation().toArray()[0]][cell.getLocation().toArray()[1]].getObject();
				// remove Stone as it is picked up and turn cell into grass
				grid[cell.getLocation().toArray()[0]][cell.getLocation().toArray()[1]].removeObject();
			}
				
			// decide viable neighbouring cells
			for (int i = 0; i < neighbourLandscape.length; i++) {
				if (neighbourLandscape[i] != null) {
					if (results.isEmpty()) {
						results.add(neighbourLandscape[i]);
					}
					// if activation is better than what is already in the collection, empty and restart
					else if (neighbourLandscape[i].getActivation() > results.get(0).getActivation() ) {
						results.clear();
						results.add(neighbourLandscape[i]);
					}
					else if (neighbourLandscape[i].getActivation() == results.get(0).getActivation()){
						results.add(neighbourLandscape[i]);
					}
				}
			}	
			// the cell to move to
			Location newLoc = results.get(Engine.random.nextInt(results.size())).getLocation();
			
			if (grid[newLoc.toArray()[0]][newLoc.toArray()[1]].getObject() instanceof Water) {
				if (carrying) {
					// add a stone to the water. action returns false if the depth is now 0							
					if (!((Water)grid[newLoc.toArray()[0]][newLoc.toArray()[1]].getObject()).addStone()) {
						// turn cell to grass by removing the object
						grid[newLoc.toArray()[0]][newLoc.toArray()[1]].removeObject();
						grid[newLoc.toArray()[0]][newLoc.toArray()[1]].addObject(null);
						partialBridgeExists = false;
						// then move onto the new bridge
						cell = grid[newLoc.toArray()[0]][newLoc.toArray()[1]];
					}
					else {
						partialBridgeExists = true;
						// don't move to the new location - stay on the current cell
					}	
					numStones++;
					carriedObject = null;
					carrying = false;
					hasDroppedinRiver = true;
				}
				else {
					cell = grid[newLoc.toArray()[0]][newLoc.toArray()[1]];
				}
			}
			else {
				cell = grid[newLoc.toArray()[0]][newLoc.toArray()[1]];
			}
			
			// if cell has object that is dangerous, e.g. Water or Trap
			if (grid[cell.getLocation().toArray()[0]][cell.getLocation().toArray()[1]].getObject() != null &&
					grid[cell.getLocation().toArray()[0]][cell.getLocation().toArray()[1]].getObject().isDangerous()) {
				isAlive = false;
			}
			
			if (cell.getObject() instanceof Resource && (targets.contains(cell.getObject()))) {
				resourcesFound++;
				grid[cell.getLocation().toArray()[0]][cell.getLocation().toArray()[1]].removeObject();
				if (resourcesFound == targets.size()) {
					// if all targets found, goal complete
					achievedGoal = true;
				}
			}
			moves++;
		}			
		return grid;
	}
	
	public String toString() {
		return decisionNetwork.toString();
	}
}